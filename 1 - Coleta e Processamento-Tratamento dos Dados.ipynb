{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coleta e Processamento/Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse notebook iremos executar os seguintes procedimentos:\n",
    "* Importação dos datasets utilizados nesse trabalho e a junção deles (acidentes agrupados por ocorrência e por pessoa)\n",
    "\n",
    "* Tratamento dos dados - exclusão de colunas que não serão utilizadas, tratamento de dados ausentes/duplicados, correção de textos, entre outras análises.\n",
    "\n",
    "* Exportação do dataset gerado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Importação e União dos datasets\n",
    "\n",
    "Os datasets utilizados nesse projeto foram baixados do site da PRF (https://portal.prf.gov.br/dados-abertos-acidentes) no dia 20/11/2020.\n",
    "\n",
    "Os datasets referentes aos acidentes agrupados por ocorrência devem ser colocados na pasta: C:\\TCC\\DATASETS\n",
    "\n",
    "Os datasets referentes aos acidentes agrupados por pessoa (de 2011 a 2015) devem ser colocados na pasta: C:\\TCC\\DATASETS\n",
    "\n",
    "Os datasets referentes aos acidentes agrupados por pessoa (de 2016 a 2020) devem ser colocados na pasta: C:\\TCC\\DATASETS\\pessoa_parte2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem 192326 linhas e 25 colunas no arquivo C:\\TCC\\DATASETS\\datatran2011.csv\n",
      "Existem 184568 linhas e 25 colunas no arquivo C:\\TCC\\DATASETS\\datatran2012.csv\n",
      "Existem 186748 linhas e 25 colunas no arquivo C:\\TCC\\DATASETS\\datatran2013.csv\n",
      "Existem 169201 linhas e 25 colunas no arquivo C:\\TCC\\DATASETS\\datatran2014.csv\n",
      "Existem 122161 linhas e 25 colunas no arquivo C:\\TCC\\DATASETS\\datatran2015.csv\n",
      "Existem 96363 linhas e 24 colunas no arquivo C:\\TCC\\DATASETS\\datatran2016_atual.csv\n",
      "Existem 89563 linhas e 29 colunas no arquivo C:\\TCC\\DATASETS\\datatran2017.csv\n",
      "Existem 69295 linhas e 29 colunas no arquivo C:\\TCC\\DATASETS\\datatran2018.csv\n",
      "Existem 67446 linhas e 29 colunas no arquivo C:\\TCC\\DATASETS\\datatran2019.csv\n",
      "Existem 45368 linhas e 29 colunas no arquivo C:\\TCC\\DATASETS\\datatran2020.csv\n",
      "Existem 1223039 linhas e 30 colunas no Dataframe gerado\n"
     ]
    }
   ],
   "source": [
    "# Importando todos os dados relativos a acidentes agrupados por ocorrência de 2011 a 2020\n",
    "# Os datasets referentes aos acidentes agrupados por ocorrência devem ser colocados na pasta: C:\\TCC\\DATASETS\n",
    "path = r'C:\\TCC\\DATASETS'\n",
    "all_files = glob.glob(path + \"/datatran*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, sep = ';', decimal=\",\", encoding = \"ISO-8859-1\",\n",
    "                     index_col=False, parse_dates=[[\"data_inversa\", \"horario\"]])\n",
    "    nRow, nCol = df.shape\n",
    "    print(f'Existem {nRow} linhas e {nCol} colunas no arquivo {filename}')\n",
    "    li.append(df)\n",
    "\n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n",
    "nRow, nCol = df.shape\n",
    "print(f'Existem {nRow} linhas e {nCol} colunas no Dataframe gerado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem 412289 linhas e 8 colunas no arquivo C:\\TCC\\DATASETS\\acidentes2011.csv\n",
      "Existem 396916 linhas e 8 colunas no arquivo C:\\TCC\\DATASETS\\acidentes2012.csv\n",
      "Existem 405820 linhas e 8 colunas no arquivo C:\\TCC\\DATASETS\\acidentes2013.csv\n",
      "Existem 368506 linhas e 8 colunas no arquivo C:\\TCC\\DATASETS\\acidentes2014.csv\n",
      "Existem 269052 linhas e 8 colunas no arquivo C:\\TCC\\DATASETS\\acidentes2015.csv\n",
      "Existem 216261 linhas e 8 colunas no arquivo C:\\TCC\\DATASETS\\pessoa_parte2\\acidentes2016_atual.csv\n",
      "Existem 204395 linhas e 8 colunas no arquivo C:\\TCC\\DATASETS\\pessoa_parte2\\acidentes2017.csv\n",
      "Existem 164802 linhas e 8 colunas no arquivo C:\\TCC\\DATASETS\\pessoa_parte2\\acidentes2018.csv\n",
      "Existem 162273 linhas e 8 colunas no arquivo C:\\TCC\\DATASETS\\pessoa_parte2\\acidentes2019.csv\n",
      "Existem 104383 linhas e 8 colunas no arquivo C:\\TCC\\DATASETS\\pessoa_parte2\\acidentes2020.csv\n",
      "Existem 2704697 linhas e 8 colunas no Dataframe gerado\n"
     ]
    }
   ],
   "source": [
    "#Importando todos os dados relativos a acidentes agrupados por pessoa de 2011 a 2020\n",
    "#Serão importadas apenas as colunas: id, tipo_veiculo, ano_fabricacao_veiculo, tipo_envolvido, sexo, idade\n",
    "path = r'C:\\TCC\\DATASETS'\n",
    "all_files = glob.glob(path + \"/acidentes*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    dfpessoas = pd.read_csv(filename, sep = ',', usecols=['id','pesid','tipo_veiculo','ano_fabricacao_veiculo','tipo_envolvido','sexo','idade','estado_fisico'], \n",
    "                            decimal=\",\", encoding = \"ISO-8859-1\", index_col=False)\n",
    "    nRow, nCol = dfpessoas.shape\n",
    "    print(f'Existem {nRow} linhas e {nCol} colunas no arquivo {filename}')\n",
    "    li.append(dfpessoas)\n",
    "\n",
    "dfpessoas = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "path = r'C:\\TCC\\DATASETS\\pessoa_parte2' # use your path\n",
    "all_files = glob.glob(path + \"/acidentes*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    dfpessoas2016a2020 = pd.read_csv(filename, sep = ';', usecols=['id','pesid','tipo_veiculo','ano_fabricacao_veiculo','tipo_envolvido','sexo','idade','estado_fisico'], \n",
    "                            decimal=\",\", encoding = \"ISO-8859-1\", index_col=False)\n",
    "    nRow, nCol = dfpessoas2016a2020.shape\n",
    "    print(f'Existem {nRow} linhas e {nCol} colunas no arquivo {filename}')\n",
    "    li.append(dfpessoas2016a2020)\n",
    "\n",
    "dfpessoas2016a2020 = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "dfpessoas = pd.concat([dfpessoas, dfpessoas2016a2020], ignore_index=True)\n",
    "nRow, nCol = dfpessoas.shape\n",
    "print(f'Existem {nRow} linhas e {nCol} colunas no Dataframe gerado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato do DataFrame:  (2704815, 37)\n"
     ]
    }
   ],
   "source": [
    "#Unindo os dois dataframes\n",
    "df = df.merge(dfpessoas, how = \"left\", on = \"id\")\n",
    "print(\"Formato do DataFrame: \", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exclusão das colunas que não serão utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato do DataFrame:  (2704815, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>br</th>\n",
       "      <th>causa_acidente</th>\n",
       "      <th>condicao_metereologica</th>\n",
       "      <th>data_inversa_horario</th>\n",
       "      <th>dia_semana</th>\n",
       "      <th>fase_dia</th>\n",
       "      <th>id</th>\n",
       "      <th>pessoas</th>\n",
       "      <th>sentido_via</th>\n",
       "      <th>tipo_acidente</th>\n",
       "      <th>...</th>\n",
       "      <th>uf</th>\n",
       "      <th>uso_solo</th>\n",
       "      <th>veiculos</th>\n",
       "      <th>pesid</th>\n",
       "      <th>tipo_veiculo</th>\n",
       "      <th>ano_fabricacao_veiculo</th>\n",
       "      <th>tipo_envolvido</th>\n",
       "      <th>estado_fisico</th>\n",
       "      <th>idade</th>\n",
       "      <th>sexo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Outras</td>\n",
       "      <td>Ceu Claro</td>\n",
       "      <td>2011-10-24 11:30:00</td>\n",
       "      <td>Segunda</td>\n",
       "      <td>Pleno dia</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Crescente</td>\n",
       "      <td>Colisão Transversal</td>\n",
       "      <td>...</td>\n",
       "      <td>SC</td>\n",
       "      <td>Urbano</td>\n",
       "      <td>2</td>\n",
       "      <td>3063879.0</td>\n",
       "      <td>Caminhão</td>\n",
       "      <td>1997</td>\n",
       "      <td>Condutor</td>\n",
       "      <td>Ileso</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Masculino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>Outras</td>\n",
       "      <td>Ceu Claro</td>\n",
       "      <td>2011-10-24 11:30:00</td>\n",
       "      <td>Segunda</td>\n",
       "      <td>Pleno dia</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Crescente</td>\n",
       "      <td>Colisão Transversal</td>\n",
       "      <td>...</td>\n",
       "      <td>SC</td>\n",
       "      <td>Urbano</td>\n",
       "      <td>2</td>\n",
       "      <td>3063899.0</td>\n",
       "      <td>Motocicletas</td>\n",
       "      <td>2008</td>\n",
       "      <td>Condutor</td>\n",
       "      <td>Ferido Grave</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Masculino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>Outras</td>\n",
       "      <td>Ceu Claro</td>\n",
       "      <td>2011-10-24 11:30:00</td>\n",
       "      <td>Segunda</td>\n",
       "      <td>Pleno dia</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Crescente</td>\n",
       "      <td>Colisão Transversal</td>\n",
       "      <td>...</td>\n",
       "      <td>SC</td>\n",
       "      <td>Urbano</td>\n",
       "      <td>2</td>\n",
       "      <td>3064114.0</td>\n",
       "      <td>Motocicletas</td>\n",
       "      <td>2008</td>\n",
       "      <td>Passageiro</td>\n",
       "      <td>Ferido Grave</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Feminino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>381</td>\n",
       "      <td>Outras</td>\n",
       "      <td>Sol</td>\n",
       "      <td>2011-10-28 06:00:00</td>\n",
       "      <td>Sexta</td>\n",
       "      <td>Amanhecer</td>\n",
       "      <td>1000001.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Decrescente</td>\n",
       "      <td>Saída de Pista</td>\n",
       "      <td>...</td>\n",
       "      <td>MG</td>\n",
       "      <td>Rural</td>\n",
       "      <td>1</td>\n",
       "      <td>3063885.0</td>\n",
       "      <td>Caminhão-Trator</td>\n",
       "      <td>1997</td>\n",
       "      <td>Condutor</td>\n",
       "      <td>Ileso</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Masculino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>407</td>\n",
       "      <td>Falta de atenção</td>\n",
       "      <td>Ceu Claro</td>\n",
       "      <td>2011-10-28 16:20:00</td>\n",
       "      <td>Sexta</td>\n",
       "      <td>Pleno dia</td>\n",
       "      <td>1000002.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Crescente</td>\n",
       "      <td>Colisão traseira</td>\n",
       "      <td>...</td>\n",
       "      <td>BA</td>\n",
       "      <td>Urbano</td>\n",
       "      <td>3</td>\n",
       "      <td>3064315.0</td>\n",
       "      <td>Automóvel</td>\n",
       "      <td>2002</td>\n",
       "      <td>Condutor</td>\n",
       "      <td>Ileso</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Masculino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    br    causa_acidente condicao_metereologica data_inversa_horario  \\\n",
       "0  101            Outras              Ceu Claro  2011-10-24 11:30:00   \n",
       "1  101            Outras              Ceu Claro  2011-10-24 11:30:00   \n",
       "2  101            Outras              Ceu Claro  2011-10-24 11:30:00   \n",
       "3  381            Outras                    Sol  2011-10-28 06:00:00   \n",
       "4  407  Falta de atenção              Ceu Claro  2011-10-28 16:20:00   \n",
       "\n",
       "  dia_semana   fase_dia         id  pessoas  sentido_via        tipo_acidente  \\\n",
       "0    Segunda  Pleno dia  1000000.0        3    Crescente  Colisão Transversal   \n",
       "1    Segunda  Pleno dia  1000000.0        3    Crescente  Colisão Transversal   \n",
       "2    Segunda  Pleno dia  1000000.0        3    Crescente  Colisão Transversal   \n",
       "3      Sexta  Amanhecer  1000001.0        1  Decrescente       Saída de Pista   \n",
       "4      Sexta  Pleno dia  1000002.0        3    Crescente     Colisão traseira   \n",
       "\n",
       "   ...  uf uso_solo veiculos      pesid     tipo_veiculo  \\\n",
       "0  ...  SC   Urbano        2  3063879.0         Caminhão   \n",
       "1  ...  SC   Urbano        2  3063899.0     Motocicletas   \n",
       "2  ...  SC   Urbano        2  3064114.0     Motocicletas   \n",
       "3  ...  MG    Rural        1  3063885.0  Caminhão-Trator   \n",
       "4  ...  BA   Urbano        3  3064315.0        Automóvel   \n",
       "\n",
       "   ano_fabricacao_veiculo tipo_envolvido estado_fisico idade       sexo  \n",
       "0                    1997       Condutor  Ileso         21.0  Masculino  \n",
       "1                    2008       Condutor  Ferido Grave  31.0  Masculino  \n",
       "2                    2008     Passageiro  Ferido Grave  -1.0   Feminino  \n",
       "3                    1997       Condutor  Ileso         57.0  Masculino  \n",
       "4                    2002       Condutor  Ileso         29.0  Masculino  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apagar do dataframe as colunas que não existem nos anos posteriores, assim como km e município\n",
    "df = df.drop(columns=['ano','latitude','longitude','regional','delegacia','uop','km','municipio','ignorados','ilesos','mortos','feridos_leves','feridos_graves','feridos','classificacao_acidente'])\n",
    "\n",
    "# ver o formato do DataFrame\n",
    "print(\"Formato do DataFrame: \", df.shape)\n",
    "\n",
    "# ver as 5 primeiras entradas dos dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tratamento de dados duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados duplicados...: 79\n",
      "Apagando os Dados duplicados...: 0\n"
     ]
    }
   ],
   "source": [
    "#Apagando os dados duplicados (sem excluir as colunas id e persid)\n",
    "print('Dados duplicados...:', df.duplicated().sum())\n",
    "df = df.drop_duplicates()\n",
    "print('Apagando os Dados duplicados...:', df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br                         1087\n",
      "causa_acidente                0\n",
      "condicao_metereologica        7\n",
      "data_inversa_horario          0\n",
      "dia_semana                    0\n",
      "fase_dia                      1\n",
      "id                            0\n",
      "pessoas                       0\n",
      "sentido_via                   0\n",
      "tipo_acidente                 0\n",
      "tipo_pista                    0\n",
      "tracado_via                   0\n",
      "uf                            0\n",
      "uso_solo                      0\n",
      "veiculos                      0\n",
      "pesid                         4\n",
      "tipo_veiculo               4002\n",
      "ano_fabricacao_veiculo    51777\n",
      "tipo_envolvido                0\n",
      "estado_fisico                 3\n",
      "idade                     98651\n",
      "sexo                        574\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Verificando se existem dados vazios no Dataframe\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato do DataFrame:  (2704732, 20)\n"
     ]
    }
   ],
   "source": [
    "#Removendo as linhas com dados ausentes da coluna pesid \n",
    "#(todas as variáveis importantes também estão ausentes) \n",
    "df.dropna(subset=['pesid'], inplace=True)\n",
    "#Apagar do dataframe as colunas restantes que não serão utilizadas\n",
    "df = df.drop(columns=['id','pesid'])\n",
    "# ver o novo formato do DataFrame\n",
    "print(\"Formato do DataFrame: \", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento dos dados de forma individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Criação dos atributos ano, mes e hora com base no atributo data_inversa_horario\n",
    "\n",
    "* Tratamento do atributo idade e criação de um novo atributo com a faixa etária das vítimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[15-24]' '[25-34]' 'Ignorada' '[55-64]' '[35-44]' '[65-74]' '[45-54]'\n",
      " '[0-4]' '[+75]' '[5-14]']\n"
     ]
    }
   ],
   "source": [
    "# Extraindo informações importantes da coluna data_inversa_horario\n",
    "df['ano'] = df['data_inversa_horario'].dt.year\n",
    "df['mes'] = df['data_inversa_horario'].dt.month\n",
    "df['hora'] = df['data_inversa_horario'].dt.hour\n",
    "df.drop(['data_inversa_horario'], axis=1, inplace = True)\n",
    "\n",
    "#Padronizando a coluna idade\n",
    "df['idade'].fillna(-1, inplace = True)\n",
    "df['idade'] = df['idade'].where(df['idade'] < 111, -1)\n",
    "\n",
    "def define_intervalo(num):\n",
    "    if num ==-1:\n",
    "        return 'Ignorada'\n",
    "    elif num <=4:\n",
    "        return '[0-4]'\n",
    "    elif num <= 14:  \n",
    "        return '[5-14]'\n",
    "    elif num <= 24:\n",
    "        return '[15-24]'\n",
    "    elif num <= 34:\n",
    "        return '[25-34]'\n",
    "    elif num <= 44:\n",
    "        return '[35-44]'\n",
    "    elif num <= 54:\n",
    "        return '[45-54]'\n",
    "    elif num <= 64:\n",
    "        return '[55-64]'\n",
    "    elif num <= 74:\n",
    "        return '[65-74]'    \n",
    "    else:\n",
    "        return '[+75]'\n",
    "\n",
    "df['faixa_etaria'] = df['idade'].apply(define_intervalo)\n",
    "df.drop(['idade'], axis=1, inplace = True)\n",
    "print(df['faixa_etaria'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Padronizando o atributo alvo desse projeto: estado_fisico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ileso', 'ferido grave', 'ferido leve', 'óbito'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['estado_fisico'] = df['estado_fisico'].str.lower()\n",
    "df['estado_fisico'] = df['estado_fisico'].str.rstrip()\n",
    "df['estado_fisico'].fillna('ileso', inplace = True)\n",
    "df['estado_fisico'] = df['estado_fisico'].str.replace('lesões graves', 'ferido grave')\n",
    "df['estado_fisico'] = df['estado_fisico'].str.replace('lesões leves', 'ferido leve')\n",
    "df['estado_fisico'] = df['estado_fisico'].str.replace('morto', 'óbito')\n",
    "df['estado_fisico'] = df['estado_fisico'].str.replace('não informado', 'ileso')\n",
    "df['estado_fisico'] = df['estado_fisico'].str.replace(\"\\(.*\\)\", 'ileso')\n",
    "df['estado_fisico'] = df['estado_fisico'].str.replace(\"ignorado\", 'ileso')\n",
    "df['estado_fisico'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Padronizando os atributos dia_semana e sexo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['segunda' 'sexta' 'quinta' 'terça' 'sábado' 'quarta' 'domingo']\n",
      "['masculino' 'feminino' 'inválido']\n"
     ]
    }
   ],
   "source": [
    "#Padronizando a coluna dia_semana\n",
    "df['dia_semana'] = df['dia_semana'].str.lower()\n",
    "df['dia_semana'] = df['dia_semana'].str.replace('-feira', '')\n",
    "print(df['dia_semana'].unique())\n",
    "\n",
    "#Padronizando a coluna sexo\n",
    "df['sexo'] = df['sexo'].str.lower()\n",
    "df['sexo'] = df['sexo'].str.replace('^m$', 'masculino')\n",
    "df['sexo'] = df['sexo'].str.replace('^f$', 'feminino')\n",
    "df['sexo'] = df['sexo'].str.replace('^i$', 'inválido')\n",
    "df['sexo'] = df['sexo'].str.replace('não informado', 'inválido')\n",
    "df['sexo'] = df['sexo'].str.replace('ignorado', 'inválido')\n",
    "df['sexo'].fillna('inválido', inplace = True)\n",
    "print(df['sexo'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Padronizando o atributo tipo_acidente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['colisão transversal', 'saída de pista', 'colisão traseira',\n",
       "       'tombamento', 'colisão lateral', 'capotamento', 'colisão frontal',\n",
       "       'derramamento de carga', 'atropelamento de animal',\n",
       "       'colisão com objeto fixo',\n",
       "       'queda de motocicleta / bicicleta / veículo',\n",
       "       'atropelamento de pedestre', 'danos eventuais',\n",
       "       'colisão com objeto móvel', 'incêndio', 'engavetamento'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tipo_acidente'] = df['tipo_acidente'].str.lower()\n",
    "df['tipo_acidente'] = df['tipo_acidente'].str.replace('colisão com objeto estático', 'colisão com objeto fixo')\n",
    "df['tipo_acidente'] = df['tipo_acidente'].str.replace('queda de ocupante de veículo', 'queda de motocicleta / bicicleta / veículo')\n",
    "df['tipo_acidente'] = df['tipo_acidente'].str.replace('atropelamento de pessoa', 'atropelamento de pedestre')\n",
    "df['tipo_acidente'] = df['tipo_acidente'].str.replace('colisão com objeto em movimento', 'colisão com objeto móvel')\n",
    "df['tipo_acidente'] = df['tipo_acidente'].str.replace('saída de leito carroçável', 'saída de pista')\n",
    "df['tipo_acidente'] = df['tipo_acidente'].str.replace('colisão com bicicleta', 'colisão com objeto móvel')\n",
    "df['tipo_acidente'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Padronizando o atributo tipo_veiculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['caminhão', 'motocicleta', 'caminhão-trator', 'automóvel',\n",
       "       'microônibus', 'caminhonete', 'camioneta', 'utilitário',\n",
       "       'bicicleta', 'motoneta', 'trator', 'não informado',\n",
       "       'não identificado', 'ônibus', 'ciclomotor', 'caminhão-tanque',\n",
       "       'carroça', 'semi-reboque', 'bonde / trem', 'reboque', 'triciclo',\n",
       "       'carro de mão', 'quadriciclo', 'motor-casa', 'outros'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.lower()\n",
    "df['tipo_veiculo'].fillna('não informado', inplace = True)\n",
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.replace(\"\\(.*\\)\", 'não informado')\n",
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.replace('micro-ônibus', 'microônibus')\n",
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.replace('semireboque', 'semi-reboque')\n",
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.replace('carroça-charrete', 'carroça')\n",
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.replace('charrete', 'carroça')\n",
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.replace('motocicletas', 'motocicleta')\n",
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.replace('side-car', 'motocicleta')\n",
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.replace('chassi-plataforma', 'outros')\n",
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.replace('carro-de-mao', 'carro de mão')\n",
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.replace('trator de esteiras', 'trator de esteira')\n",
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.replace('trator de esteira', 'trator')\n",
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.replace('trator misto', 'trator')\n",
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.replace('trator de rodas', 'trator')\n",
    "df['tipo_veiculo'] = df['tipo_veiculo'].str.replace('trem-bonde', 'bonde / trem')\n",
    "df['tipo_veiculo'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Padronizando a coluna causa_acidente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['outras', 'falta de atenção', 'velocidade incompatível',\n",
       "       'não guardar distância de segurança',\n",
       "       'defeito mecânico em veículo',\n",
       "       'desobediência às normas de trânsito pelo condutor',\n",
       "       'animais na pista', 'ultrapassagem indevida', 'ingestão de álcool',\n",
       "       'dormindo', 'defeito na via', 'fenômenos da natureza',\n",
       "       'avarias e/ou desgaste excessivo no pneu',\n",
       "       'restrição de visibilidade', 'falta de atenção do pedestre',\n",
       "       'pista escorregadia',\n",
       "       'sinalização da via insuficiente ou inadequada', 'mal súbito',\n",
       "       'carga excessiva e/ou mal acondicionada',\n",
       "       'objeto estático sobre o leito carroçável',\n",
       "       'deficiência ou não acionamento do sistema de iluminação/sinalização do veículo',\n",
       "       'ingestão de substâncias psicoativas', 'agressão externa',\n",
       "       'desobediência às normas de trânsito pelo pedestre',\n",
       "       'ingestão de álcool e/ou substâncias psicoativas pelo pedestre'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['causa_acidente'] = df['causa_acidente'].str.lower()\n",
    "df['causa_acidente'] = df['causa_acidente'].str.replace('condutor dormindo', 'dormindo')\n",
    "df['causa_acidente'] = df['causa_acidente'].str.replace('defeito mecânico no veículo', 'defeito mecânico em veículo')\n",
    "df['causa_acidente'] = df['causa_acidente'].str.replace('falta de atenção à condução', 'falta de atenção')\n",
    "df['causa_acidente'] = df['causa_acidente'].str.replace('desobediência à sinalização', 'desobediência às normas de trânsito pelo condutor')\n",
    "df['causa_acidente'] = df['causa_acidente'].str.replace(\"\\(.*\\)\", 'outras')\n",
    "df['causa_acidente'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Padronizando os atributos fase_dia, tipo_pista e tracado_via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pleno dia' 'amanhecer' 'plena noite' 'anoitecer' 'ignorado']\n",
      "['Dupla' 'Simples' 'Múltipla' 'ignorado']\n",
      "['Reta' 'Curva' 'Cruzamento' 'Não Informado' 'Interseção de vias'\n",
      " 'Rotatória' 'Desvio Temporário' 'Viaduto' 'Ponte' 'Retorno Regulamentado'\n",
      " 'Túnel']\n"
     ]
    }
   ],
   "source": [
    "#Padronizando a coluna fase_dia\n",
    "df['fase_dia'] = df['fase_dia'].str.lower()\n",
    "df['fase_dia'] = df['fase_dia'].where(df['fase_dia'] != '(null)', 'ignorado')\n",
    "df['fase_dia'].fillna('ignorado', inplace = True)\n",
    "print(df['fase_dia'].unique())\n",
    "\n",
    "#Padronizando a coluna tipo_pista\n",
    "df['tipo_pista'] = df['tipo_pista'].str.replace(\"\\(.*\\)\", 'ignorado')\n",
    "print(df['tipo_pista'].unique())\n",
    "\n",
    "#Padronizando a coluna tracado_via\n",
    "df['tracado_via'] = df['tracado_via'].str.replace(\"\\(.*\\)\", 'Não Informado')\n",
    "print(df['tracado_via'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Padronizando o atributo br e uso_solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101 381 407 116 316 376 287 467  10  20  40 364 163 317 282 158 232 343\n",
      " 153 280 369 262 277 386 222 104 470 324 285 354 319 230 242 424 304 476\n",
      " 471 135 393 392 459 359 251  50 290  60 226 356 365 174  70 408 267 259\n",
      " 406 373 472 423 465 155 401 361 428  80 493 452 293 367 156 414 412 474\n",
      " 146 488 468 235 110 487 405 402 450 330 460 447 463 427 485 308 495 210\n",
      " 404 469 480 418 377 429 410 272 419 425 421   0 416 432  30 473 498 634\n",
      " 415 349   4 140  28 661 462 352 617 580 420 221 560 654 241 499 501 489\n",
      "  84 687 178 552 453 505 183 265 426 270 441 152 681 154 767 719 323 337\n",
      " 422 851 268   2 184 648 380 591 448  37 388   1 884 250 931 436 400 433\n",
      " 211 417 186 660 434 403 435 122 482 484 457 486 451 475 430 120 342 383\n",
      " 477]\n",
      "['Urbano' 'Rural' 'ignorado']\n"
     ]
    }
   ],
   "source": [
    "#Padronizando a coluna br\n",
    "df['br'].fillna(0, inplace = True)\n",
    "df['br'] = df['br'].where(df['br'] != '(null)', '0')\n",
    "df.br = df.br.astype('uint64')\n",
    "print(df['br'].unique())\n",
    "\n",
    "#Padronizando a coluna uso_solo\n",
    "df['uso_solo'] = df['uso_solo'].str.replace('Sim', 'Urbano')\n",
    "df['uso_solo'] = df['uso_solo'].str.replace('Não', 'Rural')\n",
    "df['uso_solo'] = df['uso_solo'].where(df['uso_solo'] != '(null)', 'ignorado')\n",
    "print(df['uso_solo'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Padronizando o atributo condicao_metereologica e ano_fabricacao_veiculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ceu claro' 'sol' 'nublado' 'chuva' 'ignorada' 'vento' 'nevoeiro/neblina'\n",
      " 'neve' 'granizo' 'garoa/chuvisco']\n",
      "[1997 2008 2002 2011 2006 2007 2010 2005 2004 2009 2001 1978 1985 1969\n",
      "   -1 2000 2003 1995 1998 1981 1993 1983 1999 1994 1987 1977 1979 1996\n",
      " 1991 1989 1986 1990 1992 1980 1982 1971 1976 1974 1984 1988 1973 1975\n",
      " 1972 1970 1952 1968 1966 1954 1963 1962 1964 1967 1959 2012 1958 1965\n",
      " 1957 1851 1961 1960 2015 2013 2014 1951 1900 1950 1953 1947 1929 1928\n",
      " 1955 1956 1942 2016 1899 1919 1896 1889 1946 1897 1852 1888 1885 2019\n",
      " 1879 2017 1945 1901 1917 2018 2020]\n"
     ]
    }
   ],
   "source": [
    "#Padronizando a coluna condicao_metereologica\n",
    "df['condicao_metereologica'] = df['condicao_metereologica'].str.lower()\n",
    "df['condicao_metereologica'].fillna('ignorada', inplace = True)\n",
    "df['condicao_metereologica'] = df['condicao_metereologica'].str.replace('ignorado', 'ignorada')\n",
    "df['condicao_metereologica'] = df['condicao_metereologica'].str.replace('céu claro', 'ceu claro')\n",
    "df['condicao_metereologica'] = df['condicao_metereologica'].str.replace(\"\\(.*\\)\", 'ignorada')\n",
    "print(df['condicao_metereologica'].unique())\n",
    "\n",
    "#Padronizando a coluna ano_fabricacao_veiculo\n",
    "df['ano_fabricacao_veiculo'].fillna(-1, inplace = True)\n",
    "df['ano_fabricacao_veiculo'] = df['ano_fabricacao_veiculo'].where(df['ano_fabricacao_veiculo'] != '    ', -1)\n",
    "df['ano_fabricacao_veiculo'] = df['ano_fabricacao_veiculo'].where(df['ano_fabricacao_veiculo'] != '(null)', -1)\n",
    "df['ano_fabricacao_veiculo'] = df['ano_fabricacao_veiculo'].astype(float).astype(int)\n",
    "df['ano_fabricacao_veiculo'] = df['ano_fabricacao_veiculo'].where(df['ano_fabricacao_veiculo'] < 2021, -1)\n",
    "print(df['ano_fabricacao_veiculo'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Padronizando o atributo tipo_envolvido (só existia um registro do tipo Vítima/Proprietário de Carga/CNH, e todos eram condutores)\n",
    "\n",
    "Só existem 05 registros do tipo_envolvido igual a Ciclista. Em todos os casos, as informações importante para esse projeto\n",
    "estão ausentes. Dessa forma, decidi pela exclusão deles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Condutor', 'Passageiro', 'Pedestre', 'Cavaleiro', 'Testemunha'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tipo_envolvido'] = df['tipo_envolvido'].str.replace('Vítima', 'Condutor')\n",
    "df['tipo_envolvido'] = df['tipo_envolvido'].str.replace('Proprietário de Carga', 'Condutor')\n",
    "df['tipo_envolvido'] = df['tipo_envolvido'].str.replace('Proprietário da CNH', 'Condutor')\n",
    "\n",
    "df_remove = df.loc[df['tipo_envolvido']=='Ciclista']\n",
    "df = df.drop(df_remove.index)\n",
    "df['tipo_envolvido'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificar se ainda existem valores nulos e mostrar o novo formato do Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br                        0\n",
      "causa_acidente            0\n",
      "condicao_metereologica    0\n",
      "dia_semana                0\n",
      "fase_dia                  0\n",
      "pessoas                   0\n",
      "sentido_via               0\n",
      "tipo_acidente             0\n",
      "tipo_pista                0\n",
      "tracado_via               0\n",
      "uf                        0\n",
      "uso_solo                  0\n",
      "veiculos                  0\n",
      "tipo_veiculo              0\n",
      "ano_fabricacao_veiculo    0\n",
      "tipo_envolvido            0\n",
      "estado_fisico             0\n",
      "sexo                      0\n",
      "ano                       0\n",
      "mes                       0\n",
      "hora                      0\n",
      "faixa_etaria              0\n",
      "dtype: int64\n",
      "Novo formato do DataFrame:  (2704727, 22)\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "print(\"Novo formato do DataFrame: \", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando Processamento e Junção das Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:\\TCC\\DATASETS\\dadostratados.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
